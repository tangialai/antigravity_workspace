Metadata-Version: 2.4
Name: valtec-tts
Version: 1.0.0
Summary: Vietnamese Text-to-Speech system with simple API and auto-download
Home-page: https://github.com/yourusername/valtec-tts
Author: Valtec Team
Author-email: contact@valtec.com
Classifier: Development Status :: 4 - Beta
Classifier: Intended Audience :: Developers
Classifier: Intended Audience :: Science/Research
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Classifier: Topic :: Multimedia :: Sound/Audio :: Speech
Classifier: License :: Free For Home Use
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Requires-Python: >=3.8
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: torch>=2.0.0
Requires-Dist: torchaudio>=2.0.0
Requires-Dist: numpy>=2.0.0
Requires-Dist: scipy>=1.10.0
Requires-Dist: soundfile>=0.12.0
Requires-Dist: librosa>=0.9.0
Requires-Dist: tqdm>=4.60.0
Requires-Dist: Unidecode>=1.3.0
Requires-Dist: num2words>=0.5.10
Requires-Dist: inflect>=6.0.0
Requires-Dist: cn2an>=0.5.20
Requires-Dist: jieba>=0.42.0
Requires-Dist: pypinyin>=0.44.0
Requires-Dist: jamo>=0.4.1
Requires-Dist: gruut>=2.4.0
Requires-Dist: g2p-en>=2.1.0
Requires-Dist: anyascii>=0.3.0
Requires-Dist: viphoneme>=3.0.0
Requires-Dist: underthesea>=8.0.0
Requires-Dist: vinorm>=2.0.0
Requires-Dist: huggingface_hub>=0.20.0
Requires-Dist: eng-to-ipa>=0.0.2
Requires-Dist: gradio>=5.0.0
Provides-Extra: play
Requires-Dist: sounddevice>=0.4.0; extra == "play"
Dynamic: author
Dynamic: author-email
Dynamic: classifier
Dynamic: description
Dynamic: description-content-type
Dynamic: home-page
Dynamic: license-file
Dynamic: provides-extra
Dynamic: requires-dist
Dynamic: requires-python
Dynamic: summary

# Valtec Vietnamese TTS

Vietnamese Text-to-Speech with **Multi-Speaker TTS** and **Zero-Shot Voice Cloning**.

> **The lightest Vietnamese zero-shot voice cloning model** â€” only **74.8M parameters**, runs entirely on **CPU**, 3-4x faster than realtime. No GPU required.

## Highlights

- **ğŸª¶ Ultra-lightweight**: 74.8M params â€” the lightest Vietnamese zero-shot voice clone model
- **âš¡ CPU-only**: RTF ~0.24 on CPU (4x faster than realtime), no GPU needed
- **ğŸ¯ Zero-shot**: Clone any voice from 3-10s of audio, no fine-tuning
- **ğŸ¨ Prosody Transfer**: Transfer intonation, rhythm, emotion from reference voice
- **ğŸ‡»ğŸ‡³ Vietnamese-native**: Dedicated Vietnamese phonemizer with Northern/Southern support
- **ğŸ“¦ Multi-speaker TTS**: 5 built-in Vietnamese voices (Northern/Southern, Male/Female)
- **ğŸ”Œ Simple API**: `pip install` and use with 2 lines of code

## ğŸš€ Live Demo â€” Try it now!

| Demo | Link |
|------|------|
| **ğŸ™ï¸ Zero-Shot Voice Cloning** | [â–¶ï¸ huggingface.co/spaces/valtecAI-team/valtec-zeroshot-voice-cloning](https://huggingface.co/spaces/valtecAI-team/valtec-zeroshot-voice-cloning) |
| **ğŸ”Š Multi-Speaker TTS** | [â–¶ï¸ huggingface.co/spaces/valtecAI-team/valtec-vietnamese-tts](https://huggingface.co/spaces/valtecAI-team/valtec-vietnamese-tts) |

> Clone any voice from 3-10 seconds of audio. No GPU required. Try it directly in your browser!

**[â–¶ï¸ Watch Zero-Shot Demo Video](https://github.com/tronghieuit/valtec-tts/raw/dev/examples/ValtecTTS%20-%20ZeroShot.mp4)**

---

## ğŸ§ Zero-Shot Voice Cloning Examples

Same text, cloned with 6 different reference voices:

| Reference Voice | Description | Cloned Audio |
|----------------|-------------|--------------|
| **Thu HÃ ** | Soft female voice | [â–¶ï¸ example_thu_ha.wav](examples/zeroshot/example_thu_ha.wav) |
| **Minh Äá»©c** | Deep male voice | [â–¶ï¸ example_minh_duc.wav](examples/zeroshot/example_minh_duc.wav) |
| **Thanh TÃ¢m** | Young female voice | [â–¶ï¸ example_thanh_tam.wav](examples/zeroshot/example_thanh_tam.wav) |
| **Quang Huy** | Young male voice | [â–¶ï¸ example_quang_huy.wav](examples/zeroshot/example_quang_huy.wav) |
| **Ngá»c Ãnh** | Professional female | [â–¶ï¸ example_ngoc_anh.wav](examples/zeroshot/example_ngoc_anh.wav) |
| **HoÃ ng Nam** | Strong male voice | [â–¶ï¸ example_hoang_nam.wav](examples/zeroshot/example_hoang_nam.wav) |

### Multi-Speaker TTS Examples

| Speaker | Region | Gender | Audio |
|---------|--------|--------|-------|
| **NF** | Northern | Female | [â–¶ï¸ example_NF.wav](examples/example_NF.wav) |
| **SF** | Southern | Female | [â–¶ï¸ example_SF.wav](examples/example_SF.wav) |
| **NM1** | Northern | Male | [â–¶ï¸ example_NM1.wav](examples/example_NM1.wav) |
| **SM** | Southern | Male | [â–¶ï¸ example_SM.wav](examples/example_SM.wav) |
| **NM2** | Northern | Male | [â–¶ï¸ example_NM2.wav](examples/example_NM2.wav) |

> Clone the repo and listen to files in `examples/` for the best audio quality.

---

## âš¡ Performance â€” CPU is all you need

### Zero-Shot Voice Cloning (74.8M params)

| Component | Parameters | Purpose |
|-----------|-----------|---------|
| **Synthesizer** | 56.45M | Voice synthesis |
| **Speaker Encoder** | 8.03M | Voice identity extraction |
| **Style Encoder** | 7.80M | Prosody/style extraction |
| **Prosody Predictor** | 2.52M | F0/energy prediction |
| **Total** | **74.80M** | **~285 MB (FP32)** |

#### Zero-Shot CPU Benchmark

> Runs entirely on CPU â€” no GPU needed!

| Input Length | Inference Time | Audio Length | RTF | Speed |
|-------------|----------------|--------------|-----|-------|
| Short (16 chars) | **506ms** | 1.07s | 0.475 | **2.1x realtime** |
| Medium (60 chars) | **1,030ms** | 3.61s | 0.286 | **3.5x realtime** |
| Long (156 chars) | **2,229ms** | 9.45s | 0.236 | **4.2x realtime** |

### Multi-Speaker TTS (57.97M params)

| Mode | Short | Medium | Long |
|------|-------|--------|------|
| **CPU** (i5-14500) | 392ms / RTF 0.54 | 854ms / RTF 0.38 | 1,653ms / RTF 0.34 |
| **CUDA** (RTX 4060 Ti) | **45ms** / RTF 0.06 | **52ms** / RTF 0.02 | **69ms** / RTF 0.01 |

> **RTF (Real-Time Factor)**: Processing time / audio duration. RTF < 1 = faster than realtime.

---

## Installation

```bash
# From Git
pip install git+https://github.com/tronghieuit/valtec-tts.git

# From Source
git clone https://github.com/tronghieuit/valtec-tts.git
cd valtec-tts
pip install -e .
```

### Requirements

- Python 3.8+
- PyTorch 2.0+
- No GPU required (CUDA optional for multi-speaker acceleration)
- Linux recommended for best phonemization quality

---

## Quick Start

### Multi-Speaker TTS (2 lines)

```python
from valtec_tts import TTS

tts = TTS()  # Auto-downloads model from Hugging Face
tts.speak("Xin chÃ o cÃ¡c báº¡n", speaker="NF", output_path="hello.wav")

# Get audio array
audio, sr = tts.synthesize("Xin chÃ o cÃ¡c báº¡n", speaker="NM1")

# Available speakers: NF, SF, NM1, SM, NM2
print(tts.list_speakers())
```

### Zero-Shot Voice Cloning (2 lines)

```python
from valtec_tts import ZeroShotTTS

tts = ZeroShotTTS()  # Auto-downloads model, CPU by default
tts.clone_voice(
    text="Xin chÃ o, tÃ´i lÃ  giá»ng nÃ³i Ä‘Æ°á»£c nhÃ¢n báº£n",
    reference_audio="your_voice.wav",
    output_path="output.wav"
)

# Or get audio array
audio, sr = tts.synthesize(
    text="ÄÃ¢y lÃ  vÄƒn báº£n tiáº¿ng Viá»‡t",
    reference_audio="references/thu_ha.wav"
)
```

### Command Line

```bash
# Zero-shot voice cloning
python infer_zeroshot.py \
  --reference references/thu_ha.wav \
  --text "Buá»•i sÃ¡ng á»Ÿ thÃ nh phá»‘ báº¯t Ä‘áº§u báº±ng nhá»¯ng Ã¢m thanh quen thuá»™c" \
  --output cloned_voice.wav

# Use your own voice
python infer_zeroshot.py \
  --reference your_voice.wav \
  --text "VÄƒn báº£n tiáº¿ng Viá»‡t cá»§a báº¡n" \
  --output output.wav --cpu

# Multi-speaker TTS
python infer.py --text "Xin chÃ o cÃ¡c báº¡n" --speaker NF --output hello.wav
python infer.py --interactive
```

### Gradio Demos

```bash
# Zero-shot voice cloning demo
python app_zeroshot.py
# Open: http://localhost:7860

# Multi-speaker TTS demo
python app.py
```

---

## ğŸ¤ Zero-Shot Voice Cloning â€” Details

### Architecture

```
Reference Audio
    â”œâ”€â†’ Speaker Encoder â†’ Speaker Embedding (512-dim)
    â””â”€â†’ Mel Extraction â†’ Style Encoder â†’ Prosody Embedding (128-dim)

Input Text â†’ Vietnamese Phonemizer â†’ Text Encoder â†’ Text Representation

[Speaker Emb + Prosody Emb + Text Repr] â†’ Voice Generator â†’ Output Audio
```

#### Components

1. **Speaker Encoder (512-dim)** â€” Extracts speaker identity from raw audio waveform. L2-normalized for generalization.
2. **Style Encoder (128-dim)** â€” Extracts prosody/style from mel spectrograms (80 channels). Captures rhythm, emotion, speaking style.
3. **Prosody Predictor** â€” Predicts F0 (pitch) and energy contours from text + style embedding.
4. **Voice Generator** â€” Neural vocoder with style-dependent normalization (FiLM conditioning for F0/energy).

### Reference Audio Requirements

For best results:

| âœ… Good | âŒ Bad |
|---------|--------|
| 3-10 seconds duration | < 2s (poor representation) |
| Clean, clear speech | Noisy background |
| Single speaker | Multiple speakers |
| Neutral emotion | Extreme emotion/shouting |
| Any language | Music or sound effects |

```bash
# Prepare reference audio
ffmpeg -i full_audio.wav -ss 00:00:10 -t 5 -ar 24000 reference.wav
ffmpeg -i input.mp3 -ar 24000 -ac 1 reference.wav
```

### 6 Built-in Reference Voices

Available in `references/`:

| Voice | File | Description |
|-------|------|-------------|
| **Thu HÃ ** | `thu_ha.wav` | Soft, warm female voice |
| **Minh Äá»©c** | `minh_duc.wav` | Deep, composed male voice |
| **Thanh TÃ¢m** | `thanh_tam.wav` | Young, bright female voice |
| **Quang Huy** | `quang_huy.wav` | Young, energetic male voice |
| **Ngá»c Ãnh** | `ngoc_anh.wav` | Professional female anchor |
| **HoÃ ng Nam** | `hoang_nam.wav` | Strong, deep male voice |

> Upload your own reference audio (3-10 seconds, clear speech) to clone any voice.

### Advanced Usage

#### Speaker Interpolation

```python
# Blend two voices
spk_emb_1 = tts.extract_embeddings("voice_1.wav")[0]
spk_emb_2 = tts.extract_embeddings("voice_2.wav")[0]

alpha = 0.5  # 50-50 blend
spk_emb_mixed = alpha * spk_emb_1 + (1 - alpha) * spk_emb_2
```

### Limitations

- Vietnamese synthesis works best (model supports multiple languages but optimized for Vietnamese)
- Cannot improve upon reference audio quality
- Very unique voices may not be perfectly replicated
- Not optimized for real-time streaming (yet)

---

## ğŸ”Š Multi-Speaker TTS â€” Details

### 5 Vietnamese Voices

| Speaker | Region | Gender | Code |
|---------|--------|--------|------|
| **NF** | Northern (Miá»n Báº¯c) | Female | `NF` |
| **SF** | Southern (Miá»n Nam) | Female | `SF` |
| **NM1** | Northern (Miá»n Báº¯c) | Male | `NM1` |
| **SM** | Southern (Miá»n Nam) | Male | `SM` |
| **NM2** | Northern (Miá»n Báº¯c) | Male | `NM2` |

### Parameters

| Parameter | Default | Description |
|-----------|---------|-------------|
| `speed` | 1.0 | < 1.0 = faster, > 1.0 = slower |
| `noise_scale` | 0.667 | Voice variability |
| `noise_scale_w` | 0.8 | Duration variability |
| `sdp_ratio` | 0.0 | 0 = deterministic, 1 = stochastic |

### Model Auto-Download

Models are automatically downloaded from Hugging Face and cached:

- Windows: `%LOCALAPPDATA%\valtec_tts\models\`
- Linux/Mac: `~/.cache/valtec_tts/models/`

---

## Project Structure

```
valtec-tts/
â”œâ”€â”€ valtec_tts/           # pip install package
â”‚   â”œâ”€â”€ tts.py            # Multi-speaker TTS API
â”‚   â””â”€â”€ zeroshot.py       # Zero-shot voice cloning API
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ models/           # All model architectures
â”‚   â”‚   â”œâ”€â”€ synthesizer_zeroshot.py  # Zero-shot synthesizer
â”‚   â”‚   â”œâ”€â”€ synthesizer.py          # Multi-speaker synthesizer
â”‚   â”‚   â”œâ”€â”€ encoders.py             # Speaker/Style/Prosody encoders
â”‚   â”‚   â””â”€â”€ adain.py                # Style conditioning module
â”‚   â”œâ”€â”€ nn/               # Neural network components + mel processing
â”‚   â”œâ”€â”€ text/             # Text/phoneme processing
â”‚   â””â”€â”€ vietnamese/       # Vietnamese text normalization + phonemizer
â”œâ”€â”€ pretrained/
â”‚   â”œâ”€â”€ zeroshot/         # Zero-shot checkpoint + config
â”‚   â”œâ”€â”€ hasp/             # Speaker encoder weights
â”‚   â”œâ”€â”€ onnx/             # ONNX export models
â”‚   â””â”€â”€ config.json       # Multi-speaker config
â”œâ”€â”€ references/           # 6 reference voices for zero-shot
â”œâ”€â”€ examples/
â”‚   â”œâ”€â”€ zeroshot/         # Zero-shot cloned audio samples
â”‚   â””â”€â”€ *.wav             # Multi-speaker audio samples
â”œâ”€â”€ deployments/          # Edge / Web / Android deployments
â”œâ”€â”€ infer_zeroshot.py     # Zero-shot CLI inference
â”œâ”€â”€ infer.py              # Multi-speaker CLI inference
â”œâ”€â”€ app_zeroshot.py       # Gradio demo (zero-shot)
â””â”€â”€ app.py                # Gradio demo (multi-speaker)
```

## ğŸ“± Deployment Options

| Platform | Technology | Size | Offline |
|----------|-----------|------|---------|
| **HuggingFace Spaces** | Gradio | Cloud | No |
| **Edge** | ONNX Runtime | ~165MB | Yes |
| **Web** | ONNX Runtime Web | ~165MB | Yes |
| **Android** | ONNX Runtime Mobile | ~185MB | Yes |

See `deployments/` for detailed guides.

## Citation

```bibtex
@software{valtec_tts,
  title = {Valtec Vietnamese TTS with Zero-Shot Voice Cloning},
  author = {ValtecAI Team},
  year = {2026},
  url = {https://github.com/tronghieuit/valtec-tts}
}
```

## License

[CC BY-NC 4.0](https://creativecommons.org/licenses/by-nc/4.0/) â€” Non-commercial use only. Commercial use requires written permission.

## Acknowledgments

- Valtec AI Team for model training and development
- Vietnamese phonemization community
